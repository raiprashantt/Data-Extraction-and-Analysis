# -*- coding: utf-8 -*-
"""data_extraction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WEGn2bfWkRd-fG9FR0hRwVphd7G81x-m
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

# Load input file
input_file = '/content/Input.xlsx'
df = pd.read_excel(input_file)

# Create output directory for articles
output_dir = 'articles'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Function to extract article text
def extract_article_text(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')

        # Extract title
        title = soup.find('h1').get_text()

        # Extract article text
        paragraphs = soup.find_all('p')
        article_text = '\n'.join([para.get_text() for para in paragraphs])

        return title, article_text
    except Exception as e:
        print(f"Failed to extract from {url}: {e}")
        return None, None

# Process each URL in the input file
for index, row in df.iterrows():
    url_id = row['URL_ID']
    url = row['URL']

    title, article_text = extract_article_text(url)

    if title and article_text:
        # Save extracted text to file
        with open(f"{output_dir}/{url_id}.txt", 'w', encoding='utf-8') as file:
            file.write(f"{title}\n{article_text}")

print("Data extraction completed.")

"""# New section"""